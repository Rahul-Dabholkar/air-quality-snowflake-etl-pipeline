name: india_air_quality_json

on:
  # schedule:
  #   - cron: '45 * * * *'  # Runs every 45th minute
  workflow_dispatch:       # Allow manual trigger too

jobs:
  run-air-quality-ingestion:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout repo
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up Python
      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || pip install "snowflake-snowpark-python[pandas]" requests python-dotenv pytz

      # Step 4: Run the ETL script
      - name: Run Air Quality ETL
        env:
          # Inject all secrets securely here
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_REGION: ${{ secrets.SNOWFLAKE_REGION }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          API_KEY: ${{ secrets.API_KEY }}
          API_LIMIT: 4000
        run: |
          echo "Starting ETL job..."
          python ingest-api-data.py
